# ML News

## May 2023
* 25: BLIP-Diffusion: Image generation modelwith zero-shot editing, style transfer and more ([tweet](https://twitter.com/LiJunnan0409/status/1661537224947810304), [paper](https://hf.co/papers/2305.14720))
* 24: QLoRA: 4-bit finetuning ([tweet](https://twitter.com/Tim_Dettmers/status/1661379354507476994), [paper](https://huggingface.co/papers/2305.14314), [demo](https://huggingface.co/spaces/uwnlp/guanaco-playground-tgi))
* 22: BigCode Evaluation harness for code LLMs ([tweet](https://twitter.com/BigCodeProject/status/1660666509746917376))
* 18: VisualGLM-6B ([code](https://github.com/THUDM/VisualGLM-6B), [model](https://huggingface.co/THUDM/visualglm-6b))
* 16: PEFT Whisper ([tweet](https://twitter.com/reach_vb/status/1658463732606070785), [code](https://github.com/Vaibhavs10/fast-whisper-finetuning))
* 12: Spacy-llm, Integrating LLMs into structured NLP pipelines, Explosion ([tweet](https://twitter.com/spacy_io/status/1656734286425255937), [code](https://github.com/explosion/spacy-llm))
* 11: ProteinGeneration: diffusion in prpotein sequence space ([tweet](https://twitter.com/sid_thesci_kid/status/1656695039266013185), [paper](https://www.biorxiv.org/content/10.1101/2023.05.08.539766v1))
* 10: PaLM 2, Google ([blog](https://blog.google/technology/ai/google-palm-2-ai-large-language-model/))
* 9: StarChat: Creating a Coding Assistant with StarCoder ([tweet](https://twitter.com/_philschmid/status/1655972006616002560), [blog](https://huggingface.co/blog/starchat-alpha), [demo](https://huggingface.co/spaces/HuggingFaceH4/starchat-playground))
* 5: OpenLLaMA: An Open Reproduction of LLaMA ([tweet](https://twitter.com/yixuan_su/status/1654234602003636226), [code](https://github.com/openlm-research/open_llama), [model](https://huggingface.co/openlm-research/open_llama_7b_preview_200bt))
* 4: StarCoder, A State-of-the-Art LLM for Code ([tweet](https://twitter.com/BigCodeProject/status/1654174941976068119), [blog](https://huggingface.co/blog/starcoder), [code](https://github.com/bigcode-project/starcoder/tree/main), [model](https://huggingface.co/bigcode/starcoder))
* 3: Pi, Personal Intelligence ([tweet](https://twitter.com/inflectionAI/status/1653475948036259840), [demo](https://heypi.com/talk))

## April 2023
* 28: StableVicuna, RLHF LLM Chatbot ([tweet](https://twitter.com/StabilityAI/status/1652026192193785856), [blog](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot))
* 28: FastChat-T5: Compact, commercial-friendly chatbot ([tweet](https://twitter.com/lmsysorg/status/1652037026705985537), [code](https://github.com/lm-sys/FastChat#FastChat-T5))
* 28: DeepFloyd IF: State of the art text-to-image model that can also generate text ([text](https://twitter.com/deepfloydai/status/1651983493717532673), [demo](https://huggingface.co/spaces/DeepFloyd/IF))
* 25: HuggingChat ([tweet](https://twitter.com/ClementDelangue/status/1650908484936908808), [UI](https://huggingface.co/chat/))
* 25: MOSS, a 16B tool-augmented language model ([tweet](https://twitter.com/tianxiangsun/status/1650895260493705216), [code](https://github.com/OpenLMLab/MOSS/blob/main/README_en.md))
* 25: NeMo Guardrails (NVIDIA), ([blog](https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/), [code](https://github.com/NVIDIA/NeMo-Guardrails))
* 25: Track Anything: Segment Anything Meets Videos ([tweet](https://twitter.com/arankomatsuzaki/status/1650668065128865794))
* 24: Scaling Transformer to 1M tokens ([tweet](https://twitter.com/_akhaliq/status/1650308865555148800), [code](https://github.com/booydar/t5-experiments/tree/scaling-report))
* 20: Run Whisper 70x faster with JAX and TPU ([tweet](https://twitter.com/sanchitgandhi99/status/1649046650793648128))
* 19: StableLM ([tweet](https://twitter.com/StabilityAI/status/1648706156330876928))
* 16: CAMEL: Physics, Chemistry and Biology datasets ([tweet](https://twitter.com/hammh0a/status/1647415963644760064))
* 15: Open Assistant ([tweet](https://twitter.com/ykilcher/status/1647283816384405505), [website](https://open-assistant.io/))
* 15: ControlNet 1.1 ([tweet](https://twitter.com/huggingface/status/1647017924459126784))
* 7: SegGPT: Segmenting Everything in context ([tweet](https://twitter.com/_akhaliq/status/1644147931178496001))
* 6: Vicuna-7B weights are released ([tweet](https://twitter.com/lmsysorg/status/1644060638472470528))
* 6: StackLlama ([tweet](https://twitter.com/lvwerra/status/1643998302738759683))
* 6: VideoCrafter: text to video model ([tweet](https://twitter.com/TomLikesRobots/status/1643878218498207744))
* 6: Generative Novel View synthesis ([tweet](https://twitter.com/_akhaliq/status/1643790003779059715))
* 5: SAM - Segment anything ([tweet](https://twitter.com/MetaAI/status/1643599800414380038))
* 5: ChatArena, multi-agent game environments for LLMs ([tweet](https://twitter.com/mindjimmy/status/1643633046208249856))
* 5: Kandinsky 2.1 for image generation ([tweet](https://twitter.com/nearcyan/status/1643421466795417600))
* 5: LLaMA-Adapter ([tweet](https://twitter.com/lupantech/status/1643385891338227712))
* 5: LatentVideo Diffusion Models for long video generation ([tweet](https://twitter.com/_akhaliq/status/1643627527594815488))
* 4: MolFeat, a hub of molecular featurizers ([tweet](https://twitter.com/datamol_io/status/1643263399915311104))
* 4: LangChain announced their $10M seed round ([tweet](https://twitter.com/hwchase17/status/1643301144717066240))
* 4: Kandinsky 2.1 ([tweet](https://twitter.com/_akhaliq/status/1643191350672646144))
* 4: IGEL, an instruction-uned German LLM ([tweet](https://twitter.com/_philschmid/status/1643278444992626689))
* 4: Koala-13B: A Dialogue Model for Academic Research ([tweet](https://twitter.com/AlphaSignalAI/status/1643306708716904461), [blog](https://bair.berkeley.edu/blog/2023/04/03/koala/))
* 4: Baize: An Open-Source chat model with PEFT ([tweet](https://twitter.com/arankomatsuzaki/status/1643054506148614146))
* 3: Vicuna-13B weights are released ([tweet](https://twitter.com/lmsysorg/status/1642968294998306816))
* 3: A Survey of Large Language Models ([tweet](https://twitter.com/arankomatsuzaki/status/1642686213147738112))


## March 2023
* 30: BloombergGPT: A Large Language Model for Finance ([tweet](https://twitter.com/TechAtBloomberg/status/1641772329658114053), [paper](https://arxiv.org/abs/2303.17564))
* 30: Nucleotide Transformer, SOTA Genomics ([tweet](https://twitter.com/instadeepai/status/1641075963051012097), [code](https://github.com/instadeepai/nucleotide-transformer))
* 30: ColossalChat ([blog](https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b), [code](https://github.com/hpcaitech/ColossalAI))
* 29: GeoV-9b ([tweet](https://twitter.com/labmlai/status/1641357802009395201), [code](https://github.com/geov-ai/geov), [weights](https://huggingface.co/GeoV/GeoV-9b), [colab](https://colab.research.google.com/github/geov-ai/geov/blob/master/notebooks/generate.ipynb))
* 29: Spanish BERTIN GPT-J-6B Alpaca and Alpaca LoRA ([tweet](https://twitter.com/versae/status/1641124547414900736))
* 29: LLaMA Adapter ([tweet](https://twitter.com/lupantech/status/1640899600281395200), [code](https://github.com/ZrrSkywalker/LLaMA-Adapter), [paper](https://huggingface.co/papers/2303.16199))
* 28: PRESTO dataset ([github](https://github.com/google-research-datasets/presto))
* 28: OpenFlamingo ([tweet](https://twitter.com/anas_awadalla/status/1640766789977251840), [blog](https://laion.ai/blog/open-flamingo/))
* 28: Raven RWKV (RWKV finetuned on alpaca and codealpaca) ([tweet](https://twitter.com/BlinkDL_AI/status/1640742627216875524), [demo](https://huggingface.co/spaces/BlinkDL/Raven-RWKV-7B))
* 28: Cerebras-GPT ([tweet](https://twitter.com/CerebrasSystems/status/1640725880711569408), [models](https://huggingface.co/cerebras))
* 28: GPT4All ([tweet](https://twitter.com/andriy_mulyar/status/1640836003194630144), [code](https://github.com/nomic-ai/gpt4all))
* 28: Replit Partners with Google Cloud ([tweet](https://twitter.com/Replit/status/1640745029080866817))
* 27: LLaMA voice chat + Siri TTS ([tweet](https://twitter.com/ggerganov/status/1640416314773700608))
* 26: Japanese Alpaca LoRA ([tweet](https://twitter.com/kun1em0n/status/1639965140429963264), [demo](https://huggingface.co/spaces/kunishou/Japanese-Alpaca-LoRA-7b-DEMO), [report](https://note.com/kun1emon/n/n1533345d5d26))
* 26: LLaMA voice chat ([tweet](https://twitter.com/ggerganov/status/1640022482307502085))
* 24: Text2Video-Zero ([tweet](https://twitter.com/_akhaliq/status/1639062868850266112), [code](https://github.com/Picsart-AI-Research/Text2Video-Zero))
* 24: Dolly ([tweet](https://twitter.com/databricks/status/1639239800145465344), [code](https://github.com/databrickslabs/dolly), [demo](https://huggingface.co/databricks/dolly-v1-6b))
* 22: Alpaca LoRA as a chatbot ([tweet](https://twitter.com/algo_diver/status/1638525828773576704), [code](https://github.com/deep-diver/Alpaca-LoRA-Serve)).
* 20: Runway Gen-2 ([tweet](https://twitter.com/runwayml/status/1637800500459458562))
* 24: SwissBERT ([tweet](https://twitter.com/j_vamvas/status/1639192870828556290), [blog](https://vamvas.ch/introducing-swissbert))
* 17: Alpacoom: BLOOM fine-tuned on Alpaca's dataset using LoRA ([tweet](https://twitter.com/mrm8488/status/1636742703055527937?s=20), [model](https://huggingface.co/mrm8488/Alpacoom))
* 16: Alpaca LoRA: instruct tune LLAMA on consumer hardware ([tweet](https://twitter.com/_akhaliq/status/1636416647518097408), [code](https://github.com/tloen/alpaca-lora))
* 14: Claude, Anthropic ([blog](https://www.anthropic.com/index/introducing-claude))
* 14: ChatGLM-6B ([code](https://github.com/THUDM/ChatGLM-6B), [model](https://huggingface.co/THUDM/chatglm-6b))
